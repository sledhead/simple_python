{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOSekLV1JfMdfcuydBz8ax8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sledhead/simple_python/blob/main/webpage_scrapv4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G48MrgPaua3K"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Required Modules (Libraries)\n",
        "\n",
        "*   Link to Google Drive\n",
        "*   Install Modules to interact with xml\n",
        "*   Link Required libraries"
      ],
      "metadata": {
        "id": "i6yJeFu_uplf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "#Will display upload box to user to allow a file to upload and encrypted.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install xmltodict\n",
        "import xmltodict\n",
        "\n",
        "import time\n",
        "import os\n",
        "import shutil"
      ],
      "metadata": {
        "id": "2JOvVmDRu2Fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Senator Vote Records\n",
        "\n",
        "\n",
        "*   Get the senator vote records for each session\n",
        "*   Convert the records into individual vote tallies\n",
        "*   Provide User with ability to control time period"
      ],
      "metadata": {
        "id": "_Anv2lBVv5Ut"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Section below will gather xml file for each year of the senate vote.... 2017 to current"
      ],
      "metadata": {
        "id": "xMH_BF1ewa8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#allow the user the choice to define the begin years and end years....\n",
        "#https://www.senate.gov/legislative/votes_new.htm\n",
        "#build a list from the site above....\n",
        "#will start with 1990 and work forward to current day\n",
        "#1990 = vote_menu_101_1.xml\n",
        "\n",
        "def combine_nums(cong_id,sess_id):\n",
        "  combine_str = str(cong_id) + '_' + str(sess_id)\n",
        "  return combine_str\n",
        "\n",
        "year_lst = range(1989,2025,1)\n",
        "congress_id_lst = range(101,119,1)\n",
        "session_lst = [1,2]\n",
        "\n",
        "congress_session_lst = [ [combine_nums(congress_id_num, session_id) for session_id in session_lst ] for congress_id_num in congress_id_lst ]\n",
        "flatten_congress_session_lst = [ final_out for pair in congress_session_lst for final_out in pair ]\n",
        "#flatten_list = [j for sub in ini_list for j in sub]\n",
        "#zip()\n",
        "\n",
        "combine_congress_year = zip(year_lst,flatten_congress_session_lst)\n",
        "vote_menu_dict = {}\n",
        "\n",
        "for year_num in combine_congress_year:\n",
        "  vote_menu_dict[year_num[0]] = 'vote_menu_' + year_num[1] + '.xml'\n"
      ],
      "metadata": {
        "id": "ftO18ldCv__d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Please Select the Year Range  Min to Max { display-mode: \"form\" }\n",
        "\n",
        "min_year = '2017' # @param ['1989', '1990', '1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023', '2024']\n",
        "max_year = '2024' # @param ['1989', '1990', '1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023', '2024']\n",
        "\n",
        "#build list of full file path required by the user:\n",
        "#take the min and max and build a range of year required\n",
        "year_num_req = range(int(min_year),(int(max_year)+1),1)\n",
        "base_web_link = 'https://www.senate.gov/legislative/LIS/roll_call_lists/'\n",
        "\n",
        "web_link_lst = []\n",
        "for each_yr in year_num_req:\n",
        "  file_name_part = vote_menu_dict[each_yr]\n",
        "  complete_path = base_web_link + file_name_part\n",
        "  web_link_lst.append(complete_path)\n",
        "\n",
        "\n",
        "#now get the requested files from website....\n",
        "\n",
        "for single_web_link in web_link_lst:\n",
        "  !wget { single_web_link }"
      ],
      "metadata": {
        "id": "FjsS02fjw5Gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Section below will open xml and then use this file to build the list of file links for gather senator votes"
      ],
      "metadata": {
        "id": "ZMGQcGvIxUmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Base file path for local folder struct in vm\n",
        "current_dir = os.getcwd()\n",
        "local_base_folder_path = os.path.join(current_dir,'Senator_data')\n",
        "if( os.path.exists(local_base_folder_path) == False ):\n",
        "  os.makedirs(local_base_folder_path)\n",
        "\n",
        "congress_session_folder_names = []\n",
        "full_http_link_file_path = []\n",
        "each_vote_info = []\n",
        "#vote_menu_file_lst = ['vote_menu_115_1.xml','vote_menu_115_2.xml','vote_menu_116_1.xml','vote_menu_116_2.xml','vote_menu_117_1.xml','vote_menu_117_2.xml','vote_menu_118_1.xml','vote_menu_118_2.xml']\n",
        "\n",
        "#for each_year_call_lst in vote_menu_file_lst:\n",
        "for each_year in year_num_req:\n",
        "  file_name_part = vote_menu_dict[each_year]\n",
        "\n",
        "  xml_file = open(file_name_part, 'r')\n",
        "  xml_data_str = xml_file.read()\n",
        "\n",
        "  xml_to_dict_obj = xmltodict.parse(xml_data_str)\n",
        "\n",
        "  congress_num = xml_to_dict_obj['vote_summary']['congress']\n",
        "  congress_sec_num = xml_to_dict_obj['vote_summary']['session']\n",
        "\n",
        "  congress_lst_vote = xml_to_dict_obj['vote_summary']['votes']['vote']\n",
        "\n",
        "\n",
        "\n",
        "  base_link_path = 'https://www.senate.gov/legislative/LIS/roll_call_votes/'\n",
        "  full_base_link_path = base_link_path + 'vote' + str(congress_num) + str(congress_sec_num) + '/vote_' + str(congress_num) + '_' + str(congress_sec_num) + '_'\n",
        "  congress_session_folder_names.append('vote_' + str(congress_num) + '_' + str(congress_sec_num))\n",
        "  print(full_base_link_path)\n",
        "\n",
        "  for each_vote_section in congress_lst_vote:\n",
        "    single_vote_num = each_vote_section['vote_number']\n",
        "    single_vote_info_dict = {}\n",
        "    #build full link path for getting xml data....\n",
        "    #https://www.senate.gov/legislative/LIS/roll_call_votes/vote1172/vote_117_2_00420.htm\n",
        "\n",
        "    single_file_link_path = full_base_link_path + str(single_vote_num) + '.xml'\n",
        "    full_http_link_file_path.append(single_file_link_path)\n",
        "    single_vote_info_dict['full_http_path'] = single_file_link_path\n",
        "    single_vote_info_dict['dest_folder'] = 'vote_' + str(congress_num) + '_' + str(congress_sec_num)\n",
        "    single_vote_info_dict['file_name'] = 'vote_' + str(congress_num) + '_' + str(congress_sec_num) + '_' + str(single_vote_num) + '.xml'\n",
        "    each_vote_info.append(single_vote_info_dict)\n",
        "\n",
        "\n",
        "#section will build the temp folder directory struct for this vm instanse\n",
        "print('..............................................................')\n",
        "for new_folder_name in congress_session_folder_names:\n",
        "  #build new folder path and make\n",
        "  local_folder_path = os.path.join(current_dir,'Senator_data',new_folder_name)\n",
        "  if( os.path.exists(local_folder_path) == False ):\n",
        "    print(f'The following folder was added: {local_folder_path}')\n",
        "    os.makedirs(local_folder_path)"
      ],
      "metadata": {
        "id": "aeGCqAMjxWdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Please select local file storage only or local plus drive backup { display-mode: \"form\" }\n",
        "\n",
        "location = 'drive_backup' # @param ['local_only','drive_backup']\n",
        "backup_path = '/content/drive/MyDrive/Encryption_test/Senator_data' # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "for single_vote_xml_file in each_vote_info:\n",
        "  #get the request xml data files\n",
        "  #get the xml data files\n",
        "  if( location == 'local_only' ):\n",
        "    #just store xml file on the local vm....\n",
        "    local_dest_folder_path = os.path.join(current_dir,'Senator_data',single_vote_xml_file['dest_folder'])\n",
        "    !wget -P {local_dest_folder_path} {single_vote_xml_file['full_http_path']}\n",
        "\n",
        "  if( location == 'drive_backup'):\n",
        "    #more stuff to do...\n",
        "    #does drive path exists???\n",
        "    local_dest_folder_path = os.path.join(backup_path,single_vote_xml_file['dest_folder'])\n",
        "    if( os.path.exists(local_dest_folder_path) == False ):\n",
        "      os.makedirs(local_dest_folder_path)\n",
        "\n",
        "    #before download a new copy, check and see if it exists on the drive backup...\n",
        "    check_for_xml_file = os.path.join(backup_path,single_vote_xml_file['dest_folder'], single_vote_xml_file['file_name'])\n",
        "    if( os.path.exists(check_for_xml_file) == False ):\n",
        "      #does not exist in back_up, so download\n",
        "      !wget -P {local_dest_folder_path} {single_vote_xml_file['full_http_path']}\n",
        "\n",
        "    else:\n",
        "      #file was found...\n",
        "      print(f'Found:::::: {check_for_xml_file}')"
      ],
      "metadata": {
        "id": "Qmv-hXpTxk6h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}